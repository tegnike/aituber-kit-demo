{
  "Description": "■ Informazioni sull'applicazione",
  "BasedSettings": "■ Impostazioni di base",
  "AISettings": "■ Impostazioni IA",
  "CharacterSettings": "■ Impostazioni personaggio",
  "YoutubeSettings": "■ Impostazioni YouTube",
  "VoiceSettings": "■ Impostazioni voce",
  "SlideSettings": "■ Impostazioni presentazione",
  "LogSettings": "■ Cronologia conversazioni",
  "OtherSettings": "■ Altro",
  "ExternalLinkageMode": "Modalità collegamento esterno (WebSocket)",
  "YoutubeMode": "Modalità YouTube",
  "YoutubeInfo": "Il primo carattere del commento è '#' e verrà ignorato.",
  "YoutubeAPIKey": "Chiave API YouTube",
  "YoutubeLiveID": "ID diretta YouTube",
  "ConversationContinuityMode": "Modalità continuità conversazione (Beta)",
  "ConversationContinuityModeInfo": "Quando non ci sono commenti, l'IA cerca di continuare la conversazione. Attualmente supportato solo da OpenAI, Anthropic Claude, Google Gemini.",
  "ConversationContinuityModeInfo2": "Una risposta richiede più chiamate LLM, quindi l'utilizzo dell'API potrebbe aumentare. Si prega di tenerne conto.",
  "ConversationContinuityModeInfo3": "gpt-4, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet funzionano in modo relativamente stabile.",
  "MaxPastMessages": "Numero di messaggi passati da mantenere",
  "StatusOn": "Stato: ATTIVO",
  "StatusOff": "Stato: DISATTIVO",
  "Select": "Seleziona",
  "TestVoice": "Test voce",
  "SelectAIService": "Seleziona servizio IA",
  "LocalLLM": "LLM locale",
  "SelectModel": "Seleziona modello",
  "OpenAIAPIKeyLabel": "Chiave API OpenAI",
  "AnthropicAPIKeyLabel": "Chiave API Anthropic",
  "GoogleAPIKeyLabel": "Chiave API Google Gemini",
  "AzureAPIKeyLabel": "Chiave API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "GroqAPIKeyLabel": "Chiave API Groq",
  "CohereAPIKeyLabel": "Chiave API Cohere",
  "MistralAIAPIKeyLabel": "Chiave API MistralAI",
  "PerplexityAPIKeyLabel": "Chiave API Perplexity",
  "FireworksAPIKeyLabel": "Chiave API Fireworks",
  "DifyAPIKeyLabel": "Chiave API Dify",
  "DeepSeekAPIKeyLabel": "Chiave API DeepSeek",
  "APIKeyInstruction": "Puoi ottenere la chiave API qui sotto. Inserisci la chiave API ottenuta nel modulo.",
  "LocalLLMInfo": "Il server LLM locale deve essere in esecuzione. La configurazione è la seguente.",
  "LocalLLMInfo2": "Inserisci l'URL del server LLM locale (incluso il numero di porta) e il nome del modello.",
  "GroqInfo": "L'API Groq è accessibile direttamente dal browser.",
  "DifyInfo": "Dify supporta solo i tipi chatbot e agent.",
  "DifyInfo2": "La lunghezza della cronologia conversazioni dipende dalle specifiche di Dify.",
  "DifyInfo3": "Esempio: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Se usi Dify, il prompt di sistema non verrà utilizzato. Configura il chatbot Dify.",
  "EnterURL": "URL",
  "CharacterModelLabel": "Modello personaggio",
  "CharacterModelInfo": "Il modello potrebbe richiedere tempo per caricarsi alla prima visualizzazione.",
  "OpenVRM": "Apri VRM",
  "BackgroundImage": "Immagine di sfondo",
  "ChangeBackgroundImage": "Cambia immagine di sfondo",
  "CharacterSettingsPrompt": "Prompt personaggio",
  "CharacterSettingsInfo": "Questo valore viene impostato come prompt di sistema.\nFai riferimento al prompt iniziale e specifica i tag delle emozioni per controllare le espressioni e i movimenti del personaggio. Esempio: [neutral]Buongiorno![happy]Anche oggi sarà una giornata impegnativa!",
  "CharacterSettingsReset": "Reimposta impostazioni personaggio",
  "SyntheticVoiceEngineChoice": "Scegli motore sintesi vocale",
  "VoiceAdjustment": "Regolazione voce",
  "VoiceEngineInstruction": "Seleziona il motore di sintesi vocale che desideri utilizzare.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "Utilizza l'API Koeiromap di Koemotion. Supporta solo il giapponese. Vedi il link sotto per i dettagli.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "Utilizza VOICEVOX. Supporta solo il giapponese. Usa API locale, devi scaricare e avviare l'applicazione adatta al tuo sistema.",
  "VoicevoxSpeed": "Velocità",
  "VoicevoxPitch": "Tono",
  "VoicevoxIntonation": "Intonazione",
  "UsingAivisSpeech": "AivisSpeech",
  "AivisSpeechInfo": "Utilizza AivisSpeech. Supporta solo il giapponese. Usa API locale, devi scaricare e avviare l'applicazione adatta al tuo sistema.",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Velocità",
  "AivisSpeechPitch": "Tono",
  "AivisSpeechIntonation": "Intonazione",
  "AivisSpeechServerUrl": "URL server AivisSpeech",
  "UsingNijiVoice": "NijiVoice",
  "NijiVoiceInfo": "Utilizza API NijiVoice. Supporta solo il giapponese. La chiave API può essere ottenuta dall'URL sotto.",
  "NijiVoiceApiKey": "Chiave API NijiVoice",
  "NijiVoiceActorId": "ID attore",
  "NijiVoiceSpeed": "Velocità parlato",
  "NijiVoiceEmotionalLevel": "Livello emotivo",
  "NijiVoiceSoundDuration": "Durata audio",
  "VoicevoxServerUrl": "URL server VOICEVOX",
  "UpdateSpeakerList": "Aggiorna lista speaker",
  "UsingGoogleTTS": "Google TTS",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "Utilizza Style-Bert-VITS2. Supporta solo giapponese, inglese e cinese. Se usi API locale, scarica e avvia l'applicazione adatta. Se necessario, imposta anche la chiave API.",
  "SpeakerSelection": "Selezione speaker",
  "IncludeTimestampInUserMessage": "Includi timestamp nei messaggi utente",
  "IncludeTimestampInUserMessageInfo": "Includere il timestamp aiuta l'IA a generare risposte considerando l'ora di invio.\nInserisci la seguente stringa nel prompt di sistema:\n\n\"L'input dell'utente può includere [timestamp]. Questo è l'orario UTC al momento della richiesta, genera la risposta considerando questa informazione.\"",
  "GoogleTTSInfo": "Utilizza Google Cloud Text-to-Speech. Supporta più lingue.",
  "AuthFileInstruction": "È richiesta una chiave API o file di autenticazione. Ottienila dall'URL sotto e posizionala nella root se è un file JSON.",
  "LanguageModelURL": "Seleziona il modello linguistico dall'URL sotto.",
  "LanguageChoice": "Scelta lingua",
  "StyleBeatVITS2ServerURL": "URL server",
  "StyleBeatVITS2ApiKey": "Chiave API",
  "StyleBeatVITS2ModelID": "ID modello",
  "StyleBeatVITS2Style": "Stile",
  "StyleBeatVITS2SdpRatio": "Rapporto mix SDP/DP",
  "StyleBeatVITS2Length": "Velocità parlato",
  "ConversationHistory": "Cronologia conversazione",
  "ConversationHistoryInfo": "Gli ultimi 10 scambi vengono salvati come memoria.",
  "ConversationHistoryReset": "Reimposta cronologia conversazione",
  "NotConnectedToExternalAssistant": "Non connesso all'assistente esterno.",
  "APIKeyNotEntered": "Chiave API non inserita.",
  "ChatLog": "Log chat",
  "EnterYourQuestion": "Inserisci qui la tua domanda",
  "AnswerGenerating": "Generazione risposta",
  "AboutThisApplication": "Informazioni sull'applicazione",
  "AboutThisApplicationDescription": "Interagisci con un personaggio 3D direttamente nel browser tramite microfono o testo e sintesi vocale. Puoi cambiare il personaggio (VRM), regolare la personalità e la voce del personaggio.\nLe impostazioni possono essere modificate dal pulsante menu in alto a sinistra.",
  "AboutThisApplicationDescription2": "Se vuoi cambiare personaggio, consulta la scheda \"Impostazioni personaggio\".",
  "TechnologyIntroduction": "Introduzione tecnologia",
  "TechnologyIntroductionDescription1": "Questa applicazione è basata sul progetto <b>ChatVRM</b> di pixiv. Il codice sorgente originale è disponibile",
  "TechnologyIntroductionLink1": "qui",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Per la visualizzazione e manipolazione del modello 3D viene utilizzato",
  "TechnologyIntroductionDescription4": "Per la generazione del testo della conversazione vengono utilizzati vari LLM come",
  "TechnologyIntroductionDescription5": "Per la sintesi vocale vengono utilizzati vari motori TTS come",
  "TechnologyIntroductionDescription6": "Per maggiori dettagli, consulta questo",
  "TechnologyIntroductionLink2": "articolo esplicativo",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "Il codice sorgente di questa applicazione è condiviso su GitHub. Sei libero di modificarlo.",
  "SourceCodeDescription2": "Per l'uso commerciale, consulta il README del repository.",
  "RepositoryURL": "URL repository:",
  "DontShowIntroductionNextTime": "Non mostrare questa finestra la prossima volta",
  "Close": "CHIUDI",
  "Contact": "Contatti",
  "ContactDescription": "Per domande su questa applicazione, contattaci tramite l'indirizzo email o l'account Twitter sotto.",
  "Creator": "Creatore",
  "CreatorDescription": "Creatore: Tegan",
  "Language": "Lingua",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "Impostazioni GSVI TTS",
  "GSVITTSServerUrl": "Endpoint API GSVI TTS",
  "GSVITTSModelID": "ID modello GSVI TTS",
  "GSVITTSBatchSize": "Dimensione batch GSVI TTS (1 ~ 100 Maggiore è il valore, più veloce sarà l'inferenza, ma potrebbe esaurire la memoria se troppo grande)",
  "GSVITTSSpeechRate": "Velocità parlato (0.5 ~ 2.0 Maggiore è il valore, più veloce sarà)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "Utilizza l'API ElevenLabs. Supporta più lingue. La chiave API può essere ottenuta dall'URL sotto.",
  "ElevenLabsApiKey": "Chiave API ElevenLabs",
  "ElevenLabsVoiceId": "ID voce ElevenLabs",
  "ElevenLabsVoiceIdInfo": "L'ID voce può essere selezionato dall'URL sotto.",
  "CharacterName": "Nome personaggio",
  "ShowAssistantText": "Mostra riquadro risposta",
  "ShowCharacterName": "Mostra nome personaggio nel riquadro risposta",
  "ShowControlPanel": "Mostra pulsante impostazioni",
  "ShowControlPanelInfo": "La schermata impostazioni può essere visualizzata premendo Cmd + . (Mac) / Ctrl + . (Windows).",
  "SlideMode": "Modalità presentazione",
  "SelectedSlideDocs": "Documenti presentazione selezionati",
  "SlideModeDescription": "Questa è una modalità in cui l'IA presenta automaticamente le diapositive. Disponibile solo quando il servizio IA selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertLabel": "Conversione PDF presentazione",
  "PdfConvertDescription": "Converti PDF in dati modalità presentazione. Disponibile solo quando il servizio IA selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertFileUpload": "Seleziona file PDF",
  "PdfConvertFolderName": "Nome cartella salvataggio",
  "PdfConvertModelSelect": "Seleziona modello",
  "PdfConvertButton": "Converti PDF in presentazione",
  "PdfConvertLoading": "Conversione in corso...",
  "PdfConvertSuccess": "Conversione completata",
  "PdfConvertError": "Errore nella conversione",
  "PdfConvertSubmitError": "Assicurati che il file PDF, il nome della cartella e la chiave API siano configurati.",
  "LocalStorageReset": "Reimposta impostazioni",
  "LocalStorageResetInfo": "Le variabili d'ambiente hanno la priorità se impostate. La pagina verrà ricaricata.",
  "LocalStorageResetButton": "Reimposta impostazioni",
  "Errors": {
    "EmptyAPIKey": "La chiave API non è configurata",
    "AIInvalidProperty": "La configurazione del servizio IA non è corretta",
    "AIAPIError": "Si è verificato un errore durante l'esecuzione dell'API IA",
    "InvalidAIService": "Il servizio IA selezionato non è valido",
    "MethodNotAllowed": "La richiesta non è appropriata",
    "TTSServiceError": "Si è verificato un errore nel servizio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Si è verificato un errore imprevisto",
    "LocalLLMError": "Errore LLM locale",
    "LocalLLMStreamError": "Errore stream LLM locale",
    "LocalLLMConnectionError": "Errore connessione al server LLM locale",
    "LocalLLMNotFound": "Endpoint LLM locale non trovato",
    "LocalLLMAPIError": "Errore API LLM locale"
  },
  "MessageReceiver": "Ricevi istruzioni dall'esterno",
  "MessageReceiverDescription": "Puoi usare l'API per far parlare i personaggi IA dall'esterno.",
  "ClientID": "ID cliente",
  "OpenSendMessagePage": "Apri pagina invio messaggio",
  "RealtimeAPIMode": "Modalità API in tempo reale",
  "RealtimeAPIModeContentType": "Tipo di invio",
  "RealtimeAPIModeVoice": "Tipo di voce",
  "AudioMode": "Modalità audio (Beta)",
  "InputText": "Testo",
  "InputAudio": "Audio",
  "SearchGrounding": "Usa ricerca contestuale",
  "SearchGroundingDescription": "Quando si usa la funzione multimodale, la funzione di ricerca viene disattivata automaticamente.",
  "UpdateRealtimeAPISettings": "Aggiorna impostazioni API in tempo reale",
  "UpdateRealtimeAPISettingsInfo": "Quando aggiorni la chiave API, endpoint Azure, tipo di voce, modello o prompt di sistema, premi il pulsante di aggiornamento per avviare una nuova sessione WebSocket.",
  "AzureEndpoint": "Endpoint Azure",
  "Toasts": {
    "WebSocketConnectionError": "Errore connessione WebSocket",
    "WebSocketConnectionClosed": "Connessione WebSocket chiusa",
    "WebSocketConnectionAttempt": "Tentativo connessione WebSocket...",
    "WebSocketConnectionSuccess": "Connessione WebSocket riuscita",
    "FunctionExecuting": "Esecuzione {{funcName}}",
    "FunctionExecutionFailed": "Esecuzione {{funcName}} fallita",
    "FirefoxNotSupported": "Questa funzione non è supportata in Firefox",
    "SpeechRecognitionError": "Si è verificato un errore di riconoscimento vocale"
  },
  "UsingOpenAITTS": "Usando OpenAI",
  "OpenAITTSInfo": "Usando OpenAI. Supporta più lingue. Se selezioni OpenAI come servizio IA, non devi configurare la chiave API sotto.",
  "OpenAITTSVoice": "Tipo di voce",
  "OpenAITTSModel": "Modello",
  "OpenAITTSSpeed": "Velocità",
  "UsingAzureTTS": "Usando Azure OpenAI",
  "AzureTTSInfo": "Usando Azure OpenAI. Supporta più lingue.",
  "SendMessage": {
    "title": "Adattatore esterno AITuberKit",
    "directSendTitle": "Parla direttamente al personaggio IA",
    "directSendDescription": "Puoi inviare il messaggio direttamente al personaggio IA. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello vocale è quello selezionato nelle impostazioni di AITuberKit.",
    "aiGenerateTitle": "Genera risposta IA e poi parla",
    "aiGenerateDescription": "L'IA genera una risposta dal messaggio inviato e poi la pronuncia. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello IA e il modello vocale sono quelli selezionati nelle impostazioni di AITuberKit. Il prompt di sistema può essere selezionato per usare il prompt di sistema di AITuberKit o un prompt di sistema personalizzato. Se vuoi caricare la cronologia conversazioni precedente, includi la stringa [conversation_history] nel prompt di sistema o nel messaggio utente.",
    "useCurrentSystemPrompt": "Usa prompt di sistema AITuberKit",
    "userInputTitle": "Invia input utente",
    "userInputDescription": "Il messaggio inviato viene elaborato come quando viene inserito dal modulo di input di AITuberKit. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello IA e il modello vocale sono quelli selezionati nelle impostazioni di AITuberKit. Il prompt di sistema e la cronologia conversazioni sono i valori configurati in AITuberKit."
  },
  "CannotUseVoice": "La modalità API in tempo reale o la modalità audio è attiva, quindi non sono richieste impostazioni vocali.",
  "Live2D": {
    "FileInfo": "Posiziona il modello Live2D che vuoi usare nella cartella public/live2d. Il file model3.json deve esistere nella root di questa cartella.\nSe non viene visualizzato nella selezione, ricarica la schermata o verifica che il percorso della cartella sia corretto.",
    "Info": "Puoi specificare emozioni e movimenti.\nOgni emozione è controllata dal prompt. Per maggiori dettagli, consulta \"Impostazioni IA => Impostazioni personaggio\".",
    "Emotions": "Impostazioni emozioni",
    "EmotionInfo": "Le emozioni possono essere specificate in formato separato da virgole. Se vengono specificate più emozioni, vengono selezionate casualmente.\nIl valore iniziale è per il modello fornito da AITuberKit. Se stai usando un modello originale, inserisci il valore secondo il tuo modello.\nDopo il completamento della conversazione, viene mostrata l'emozione \"Neutrale\".",
    "neutralEmotions": "Neutrale",
    "happyEmotions": "Felice",
    "sadEmotions": "Triste",
    "angryEmotions": "Arrabbiato",
    "relaxedEmotions": "Rilassato",
    "MotionGroups": "Impostazioni gruppi movimento",
    "MotionGroupsInfo": "I gruppi di movimento vengono selezionati casualmente dal gruppo selezionato.\nCome per le impostazioni emozioni, configuralo secondo il tuo modello.\n\"Idle\" è il movimento mostrato dopo il completamento della conversazione.",
    "SelectMotionGroup": "Seleziona gruppo movimento",
    "idleMotionGroup": "Inattivo",
    "neutralMotionGroup": "Neutrale",
    "happyMotionGroup": "Felice",
    "sadMotionGroup": "Triste",
    "angryMotionGroup": "Arrabbiato",
    "relaxedMotionGroup": "Rilassato"
  },
  "UseVideoAsBackground": "Usa schermo condiviso o webcam come sfondo",
  "Temperature": "Temperatura"
}
