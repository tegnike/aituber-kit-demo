{
  "Description": "■ حول التطبيق",
  "BasedSettings": "■ الإعدادات الأساسية",
  "AISettings": "■ إعدادات الذكاء الاصطناعي",
  "CharacterSettings": "■ إعدادات الشخصية",
  "YoutubeSettings": "■ إعدادات يوتيوب",
  "VoiceSettings": "■ إعدادات الصوت",
  "SlideSettings": "■ إعدادات العرض التقديمي",
  "LogSettings": "■ سجل المحادثات",
  "OtherSettings": "■ إعدادات أخرى",
  "ExternalLinkageMode": "وضع الربط الخارجي (نسخة تجريبية)",
  "YoutubeMode": "وضع يوتيوب",
  "YoutubeInfo": "إذا كان الحرف الأول من التعليق هو '#'، يتم تجاهله.",
  "YoutubeAPIKey": "مفتاح API يوتيوب",
  "YoutubeLiveID": "معرف البث المباشر على يوتيوب",
  "ConversationContinuityMode": "وضع استمرارية المحادثة (تجريبي)",
  "ConversationContinuityModeInfo": "عندما لا يكون هناك تعليق، يحاول الذكاء الاصطناعي مواصلة المحادثة. حالياً يدعم فقط OpenAI وAnthropicClaude وGoogle Gemini.",
  "ConversationContinuityModeInfo2": "كل إجابة تستدعي LLM عدة مرات، لذا قد يزيد استخدام API. يرجى الانتباه لذلك.",
  "ConversationContinuityModeInfo3": "gpt-4o وgpt-4-turbo وclaude-3-opus وclaude-3.5-sonnet تعمل بشكل مستقر نسبياً.",
  "MaxPastMessages": "عدد الرسائل السابقة للاحتفاظ بها",
  "StatusOn": "الحالة: تشغيل",
  "StatusOff": "الحالة: إيقاف",
  "Select": "اختيار",
  "TestVoice": "اختبار الصوت",
  "SelectAIService": "اختيار خدمة الذكاء الاصطناعي",
  "LocalLLM": "LLM محلي",
  "SelectModel": "اختيار النموذج",
  "OpenAIAPIKeyLabel": "مفتاح API OpenAI",
  "AnthropicAPIKeyLabel": "مفتاح API Anthropic",
  "GoogleAPIKeyLabel": "مفتاح API Google Gemini",
  "AzureAPIKeyLabel": "مفتاح API Azure OpenAI",
  "AzureAPIURL": "رابط API Azure OpenAI",
  "GroqAPIKeyLabel": "مفتاح API Groq",
  "CohereAPIKeyLabel": "مفتاح API Cohere",
  "MistralAIAPIKeyLabel": "مفتاح API MistralAI",
  "PerplexityAPIKeyLabel": "مفتاح API Perplexity",
  "FireworksAPIKeyLabel": "مفتاح API Fireworks",
  "DifyAPIKeyLabel": "مفتاح API Dify",
  "DeepSeekAPIKeyLabel": "مفتاح API DeepSeek",
  "APIKeyInstruction": "يمكنك الحصول على مفتاح API أدناه. أدخل مفتاح API الذي حصلت عليه في النموذج.",
  "LocalLLMInfo": "يجب أن يكون خادم LLM المحلي قيد التشغيل. الإعداد كما يلي.",
  "LocalLLMInfo2": "الرجاء إدخال عنوان URL لخادم LLM المحلي (متضمناً رقم المنفذ) واسم النموذج.",
  "GroqInfo": "يتم الوصول إلى Groq API مباشرة من المتصفح.",
  "DifyInfo": "Dify يدعم فقط نوع chatbot وagent.",
  "DifyInfo2": "طول سجل المحادثة يعتمد على مواصفات Dify.",
  "DifyInfo3": "مثال: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "إذا كنت تستخدم Dify، لن يتم استخدام النص التمهيدي للنظام. يرجى إعداد chatbot Dify.",
  "EnterURL": "URL",
  "CharacterModelLabel": "نموذج الشخصية",
  "CharacterModelInfo": "قد يستغرق تحميل النموذج وقتاً عند عرضه لأول مرة.",
  "OpenVRM": "فتح VRM",
  "BackgroundImage": "صورة الخلفية",
  "ChangeBackgroundImage": "تغيير صورة الخلفية",
  "CharacterSettingsPrompt": "نص الشخصية",
  "CharacterSettingsInfo": "يتم تعيين هذه القيمة كنص تمهيدي للنظام.\nيرجى الرجوع إلى النص التمهيدي الأولي وتحديد علامات المشاعر للتحكم في تعبيرات وحركات الشخصية. مثال: [neutral]صباح الخير![happy]اليوم أيضاً يوم صعب!",
  "CharacterSettingsReset": "إعادة تعيين إعدادات الشخصية",
  "SyntheticVoiceEngineChoice": "اختيار محرك الصوت الاصطناعي",
  "VoiceAdjustment": "ضبط الصوت",
  "VoiceEngineInstruction": "اختر محرك الصوت الاصطناعي الذي تريد استخدامه.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "استخدام Koeiromap API من Koemotion. يدعم اللغة اليابانية فقط. لمزيد من التفاصيل، يرجى الرجوع إلى الرابط أدناه.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "استخدام VOICEVOX. يدعم اللغة اليابانية فقط. يستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "VoicevoxSpeed": "السرعة",
  "VoicevoxPitch": "درجة الصوت",
  "VoicevoxIntonation": "نبرة الصوت",
  "UsingAivisSpeech": "AivisSpeech",
  "AivisSpeechInfo": "استخدام AivisSpeech. يدعم اللغة اليابانية فقط. يستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "AivisSpeechSpeaker": "المتحدث",
  "AivisSpeechSpeed": "السرعة",
  "AivisSpeechPitch": "درجة الصوت",
  "AivisSpeechIntonation": "نبرة الصوت",
  "AivisSpeechServerUrl": "عنوان خادم AivisSpeech",
  "UsingNijiVoice": "NijiVoice",
  "NijiVoiceInfo": "يتم استخدام NijiVoice API. يدعم اللغة اليابانية فقط. يمكن الحصول على مفتاح API من الرابط أدناه.",
  "NijiVoiceApiKey": "مفتاح API NijiVoice",
  "NijiVoiceActorId": "معرف الممثل",
  "NijiVoiceSpeed": "سرعة الكلام",
  "NijiVoiceEmotionalLevel": "مستوى العاطفة",
  "NijiVoiceSoundDuration": "مدة الصوت",
  "VoicevoxServerUrl": "عنوان خادم VOICEVOX",
  "UpdateSpeakerList": "تحديث قائمة المتحدثين",
  "UsingGoogleTTS": "استخدام Google Text-to-Speech",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "استخدام Style-Bert-VITS2. يدعم اللغة اليابانية والإنجليزية والصينية فقط. إذا كنت تستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه. يرجى أيضاً إعداد مفتاح API إذا لزم الأمر.",
  "SpeakerSelection": "اختيار المتحدث",
  "IncludeTimestampInUserMessage": "تضمين الطابع الزمني في رسالة المستخدم",
  "IncludeTimestampInUserMessageInfo": "من خلال تضمين الطوابع الزمنية في رسائل المستخدم، يمكن للذكاء الاصطناعي إنشاء ردود مع مراعاة الوقت.\nيرجى تضمين النص التالي في النص التمهيدي للنظام:\n\n\"قد يتضمن إدخال المستخدم [timestamp]. هذا يمثل وقت UTC في لحظة الطلب، لذا يرجى إنشاء ردود مع مراعاة هذا الطابع الزمني.\"",
  "GoogleTTSInfo": "استخدام Google Cloud Text-to-Speech. يدعم لغات متعددة.",
  "AuthFileInstruction": "مفتاح API أو ملف المصادقة مطلوب. احصل عليه من الرابط أدناه وضعه في المجلد الجذر للمستودع إذا كان ملف JSON.",
  "LanguageModelURL": "اختر نموذج اللغة من الرابط أدناه.",
  "LanguageChoice": "اختيار اللغة",
  "StyleBeatVITS2ServerURL": "عنوان الخادم",
  "StyleBeatVITS2ApiKey": "مفتاح API",
  "StyleBeatVITS2ModelID": "معرف النموذج",
  "StyleBeatVITS2Style": "النمط",
  "StyleBeatVITS2SdpRatio": "نسبة خلط SDP/DP",
  "StyleBeatVITS2Length": "معدل الكلام",
  "ConversationHistory": "سجل المحادثات",
  "ConversationHistoryInfo": "سيتم الاحتفاظ بأحدث {{count}} محادثات كذاكرة.",
  "ConversationHistoryReset": "إعادة تعيين سجل المحادثات",
  "NotConnectedToExternalAssistant": "غير متصل بمساعد خارجي.",
  "APIKeyNotEntered": "لم يتم إدخال مفتاح API.",
  "ChatLog": "سجل المحادثة",
  "EnterYourQuestion": "أدخل سؤالك هنا",
  "AnswerGenerating": "جاري إنشاء الإجابة",
  "AboutThisApplication": "حول هذا التطبيق",
  "AboutThisApplicationDescription": "استمتع بالمحادثات مع شخصية ثلاثية الأبعاد مباشرة في متصفحك، باستخدام الميكروفون أو إدخال النص وتوليف الصوت. يمكنك أيضاً تغيير الشخصية (VRM)، وضبط شخصيتها، وتعديل صوتها.<br />يمكن تغيير الإعدادات من زر القائمة في الأعلى اليسار.",
  "AboutThisApplicationDescription2": "إذا كنت تريد تغيير الشخصية، يرجى الرجوع إلى علامة تبويب \"إعدادات الشخصية\".",
  "TechnologyIntroduction": "مقدمة التقنية",
  "TechnologyIntroductionDescription1": "تم إنشاء هذا التطبيق عن طريق تعديل <b>ChatVRM</b> من pixiv. يمكن العثور على الكود المصدري الأصلي",
  "TechnologyIntroductionLink1": "هنا",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "لعرض ومعالجة النماذج ثلاثية الأبعاد،",
  "TechnologyIntroductionDescription4": "يتم استخدام. لتوليد نص المحادثة، يتم استخدام نماذج LLM مختلفة مثل",
  "TechnologyIntroductionDescription5": "يتم استخدام. لتوليف الكلام، يتم استخدام محركات TTS مختلفة مثل",
  "TechnologyIntroductionDescription6": "يتم استخدام. لمزيد من التفاصيل، يرجى الاطلاع على هذا",
  "TechnologyIntroductionLink2": "المقال التوضيحي",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "الكود المصدري لهذا التطبيق متاح للعموم على GitHub. لا تتردد في تعديله وتكييفه كما تريد.",
  "SourceCodeDescription2": "للاستخدام التجاري، يرجى الرجوع إلى ملف README في نفس المستودع.",
  "RepositoryURL": "رابط المستودع:",
  "DontShowIntroductionNextTime": "لا تظهر هذا الحوار في المرة القادمة",
  "Close": "إغلاق",
  "Contact": "اتصل بنا",
  "ContactDescription": "يرجى الاتصال بي عبر عنوان البريد الإلكتروني أو حساب تويتر أدناه بخصوص هذا التطبيق.",
  "Creator": "المنشئ",
  "CreatorDescription": "المنشئ: Tegan",
  "Language": "اللغة",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "إعدادات GSVI TTS",
  "GSVITTSServerUrl": "نقطة نهاية API GSVI TTS",
  "GSVITTSModelID": "معرف نموذج GSVI TTS",
  "GSVITTSBatchSize": "حجم الدفعة GSVI TTS (1 ~ 100 كلما كانت القيمة أكبر، كانت سرعة الاستدلال أسرع، ولكن قد تستنفد الذاكرة إذا كانت كبيرة جداً.)",
  "GSVITTSSpeechRate": "معدل الكلام (0.5 ~ 2.0 كلما كانت القيمة أكبر، كان أسرع.)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "يتم استخدام ElevenLabs API. يدعم لغات متعددة. يمكن الحصول على مفتاح API من الرابط أدناه.",
  "ElevenLabsApiKey": "مفتاح API ElevenLabs",
  "ElevenLabsVoiceId": "معرف صوت ElevenLabs",
  "ElevenLabsVoiceIdInfo": "يمكن اختيار معرف الصوت من الرابط أدناه.",
  "CharacterName": "اسم الشخصية",
  "ShowAssistantText": "إظهار مربع الإجابة",
  "ShowCharacterName": "إظهار اسم الشخصية في مربع الإجابة",
  "ShowControlPanel": "إظهار زر الإعدادات",
  "ShowControlPanelInfo": "يمكن عرض شاشة الإعدادات بالضغط على Cmd + . (Mac) / Ctrl + . (Windows).",
  "SlideMode": "وضع العرض التقديمي",
  "SelectedSlideDocs": "مستندات العرض المحددة",
  "SlideModeDescription": "هذا وضع حيث يقدم الذكاء الاصطناعي العروض التقديمية تلقائياً. متاح فقط عندما تكون خدمة الذكاء الاصطناعي المحددة هي OpenAI أو Anthropic Claude أو Google Gemini.",
  "PdfConvertLabel": "تحويل PDF إلى عرض تقديمي",
  "PdfConvertDescription": "تحويل PDF إلى بيانات وضع العرض التقديمي. متاح فقط عندما تكون خدمة الذكاء الاصطناعي المحددة هي OpenAI أو Anthropic Claude أو Google Gemini.",
  "PdfConvertFileUpload": "اختيار ملف PDF",
  "PdfConvertFolderName": "اسم مجلد الحفظ",
  "PdfConvertModelSelect": "اختيار النموذج",
  "PdfConvertButton": "تحويل PDF إلى عرض تقديمي",
  "PdfConvertLoading": "جاري التحويل...",
  "PdfConvertSuccess": "اكتمل التحويل",
  "PdfConvertError": "فشل التحويل",
  "PdfConvertSubmitError": "يرجى التأكد من تعيين ملف PDF واسم المجلد ومفتاح API.",
  "LocalStorageReset": "إعادة تعيين الإعدادات",
  "LocalStorageResetInfo": "تكون متغيرات البيئة لها الأولوية إذا تم تعيينها. سيتم إعادة تحميل الصفحة.",
  "LocalStorageResetButton": "إعادة تعيين الإعدادات",
  "Errors": {
    "EmptyAPIKey": "لم يتم تعيين مفتاح API",
    "AIInvalidProperty": "إعدادات خدمة الذكاء الاصطناعي غير صحيحة",
    "AIAPIError": "حدث خطأ أثناء تنفيذ API الذكاء الاصطناعي",
    "InvalidAIService": "خدمة الذكاء الاصطناعي المحددة غير صالحة",
    "MethodNotAllowed": "الطلب غير مناسب",
    "TTSServiceError": "حدث خطأ في خدمة {{serviceName}} TTS: {{message}}",
    "UnexpectedError": "حدث خطأ غير متوقع",
    "LocalLLMError": "خطأ في LLM المحلي",
    "LocalLLMStreamError": "خطأ في تدفق LLM المحلي",
    "LocalLLMConnectionError": "خطأ في الاتصال بخادم LLM المحلي",
    "LocalLLMNotFound": "لم يتم العثور على نقطة نهاية LLM المحلي",
    "LocalLLMAPIError": "خطأ في API LLM المحلي"
  },
  "MessageReceiver": "تلقي التعليمات من الخارج",
  "MessageReceiverDescription": "يمكنك استخدام API لتوجيه شخصيات الذكاء الاصطناعي للتحدث من الخارج.",
  "ClientID": "معرف العميل",
  "OpenSendMessagePage": "فتح صفحة إرسال الرسائل",
  "RealtimeAPIMode": "وضع API في الوقت الفعلي",
  "RealtimeAPIModeContentType": "نوع الإرسال",
  "RealtimeAPIModeVoice": "نوع الصوت",
  "AudioMode": "وضع الصوت",
  "InputText": "النص",
  "InputAudio": "الصوت",
  "SearchGrounding": "استخدام البحث الأرضي",
  "SearchGroundingDescription": "عند استخدام ميزة متعددة الوسائط، يتم تعطيل وظيفة البحث تلقائياً.",
  "UpdateRealtimeAPISettings": "تحديث إعدادات API في الوقت الفعلي",
  "UpdateRealtimeAPISettingsInfo": "عند تحديث مفتاح API، نقطة نهاية Azure، نوع الصوت، النموذج، أو النص التمهيدي للنظام، يرجى الضغط على زر التحديث لبدء جلسة WebSocket جديدة.",
  "AzureEndpoint": "نقطة نهاية Azure",
  "Toasts": {
    "WebSocketConnectionError": "حدث خطأ في اتصال WebSocket",
    "WebSocketConnectionClosed": "تم إغلاق اتصال WebSocket",
    "WebSocketConnectionAttempt": "محاولة اتصال WebSocket...",
    "WebSocketConnectionSuccess": "نجح اتصال WebSocket",
    "FunctionExecuting": "جاري تنفيذ {{funcName}}",
    "FunctionExecutionFailed": "فشل تنفيذ {{funcName}}",
    "FirefoxNotSupported": "هذه الميزة غير مدعومة على Firefox",
    "SpeechRecognitionError": "حدث خطأ في التعرف على الكلام"
  },
  "UsingOpenAITTS": "استخدام OpenAI",
  "OpenAITTSInfo": "استخدام OpenAI. يدعم لغات متعددة. إذا اخترت OpenAI كخدمة ذكاء اصطناعي، فلا تحتاج إلى تعيين مفتاح API أدناه.",
  "OpenAITTSVoice": "نوع الصوت",
  "OpenAITTSModel": "النموذج",
  "OpenAITTSSpeed": "السرعة",
  "UsingAzureTTS": "استخدام Azure OpenAI",
  "AzureTTSInfo": "استخدام Azure OpenAI. يدعم لغات متعددة.",
  "SendMessage": {
    "title": "محول AITuberKit الخارجي",
    "directSendTitle": "التحدث مباشرة إلى شخصية الذكاء الاصطناعي",
    "directSendDescription": "يمكنك إرسال الرسالة مباشرة إلى شخصية الذكاء الاصطناعي. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الصوت هو المحدد في إعدادات AITuberKit.",
    "aiGenerateTitle": "توليد رد الذكاء الاصطناعي ثم التحدث",
    "aiGenerateDescription": "يولد الذكاء الاصطناعي رداً من الرسالة المرسلة ثم يتحدث به. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الذكاء الاصطناعي ونموذج الصوت هما المحددان في إعدادات AITuberKit. يمكن اختيار النص التمهيدي للنظام لاستخدام النص التمهيدي لنظام AITuberKit أو نص تمهيدي مخصص. إذا كنت تريد تحميل سجل المحادثة السابق، قم بتضمين السلسلة [conversation_history] في النص التمهيدي للنظام أو رسالة المستخدم.",
    "useCurrentSystemPrompt": "استخدام النص التمهيدي لنظام AITuberKit",
    "userInputTitle": "إرسال إدخال المستخدم",
    "userInputDescription": "تتم معالجة الرسالة المرسلة بنفس طريقة الإدخال من نموذج إدخال AITuberKit. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الذكاء الاصطناعي ونموذج الصوت هما المحددان في إعدادات AITuberKit. النص التمهيدي للنظام وسجل المحادثة هما القيم المعينة في AITuberKit."
  },
  "CannotUseVoice": "تم تمكين وضع API في الوقت الفعلي أو وضع الصوت، لذا لا تحتاج إلى إعدادات الصوت.",
  "Live2D": {
    "FileInfo": "ضع نموذج Live2D الذي تريد استخدامه في مجلد public/live2d. يجب أن يوجد ملف model3.json في جذر هذا المجلد.\nإذا لم يتم عرضه في الاختيار، يرجى إعادة تحميل الشاشة أو التحقق من صحة مسار المجلد.",
    "Info": "يمكنك تحديد المشاعر والحركات.\nيتم التحكم في كل عاطفة من خلال النص التمهيدي. لمزيد من التفاصيل، يرجى الرجوع إلى \"إعدادات الذكاء الاصطناعي => إعدادات الشخصية\".",
    "Emotions": "إعدادات المشاعر",
    "EmotionInfo": "يمكن تحديد المشاعر بتنسيق مفصول بفواصل. إذا تم تحديد مشاعر متعددة، يتم اختيارها عشوائياً.\nالقيمة الأولية هي للنموذج المقدم من AITuberKit. إذا كنت تستخدم نموذجاً أصلياً، يرجى إدخال القيمة وفقاً لنموذجك.\nبعد اكتمال المحادثة، يتم عرض عاطفة \"محايد\".",
    "neutralEmotions": "محايد",
    "happyEmotions": "سعيد",
    "sadEmotions": "حزين",
    "angryEmotions": "غاضب",
    "relaxedEmotions": "مسترخي",
    "MotionGroups": "إعدادات مجموعة الحركة",
    "MotionGroupsInfo": "يتم اختيار مجموعات الحركة عشوائياً من المجموعة المحددة.\nمثل إعدادات المشاعر، يرجى تعيينها وفقاً لنموذجك.\n\"خامل\" هي الحركة المعروضة بعد اكتمال المحادثة.",
    "SelectMotionGroup": "اختيار مجموعة الحركة",
    "idleMotionGroup": "خامل",
    "neutralMotionGroup": "محايد",
    "happyMotionGroup": "سعيد",
    "sadMotionGroup": "حزين",
    "angryMotionGroup": "غاضب",
    "relaxedMotionGroup": "مسترخي"
  },
  "UseVideoAsBackground": "استخدام الشاشة المشتركة أو كاميرا الويب كخلفية",
  "Temperature": "درجة الحرارة",
  "MaxTokens": "أقصى عدد من الرموز",
  "MaxTokensInfo": "يختلف أقصى عدد من الرموز حسب نموذج الذكاء الاصطناعي المستخدم. يرجى التحقق من مواصفات كل نموذج.",
  "CannotUseParameters": "إذا كان وضع API في الوقت الحقيقي أو وضع الصوت مفعلًا، فلا يمكن تحديد معلمات Temperature و Max Tokens.",
  "DocumentationDescription": "يمكنك الاطلاع على كيفية استخدام AITuberKit والدروس التعليمية التفصيلية من خلال الرابط أدناه."
}